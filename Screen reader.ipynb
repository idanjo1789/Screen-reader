{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec391c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GameReaper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging, time\n",
    "import re\n",
    "import pyperclip\n",
    "from PIL import Image\n",
    "from tkinter import Tk, Canvas\n",
    "import pyautogui, keyboard\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "from numpy.dtypes import Float64DType\n",
    "import os, numpy as np, torch, sounddevice as sd\n",
    "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
    "from numpy.dtypes import Float64DType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b418326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "def extract_text_from_image(pil_image: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    מקבל PIL.Image, מחזיר את הטקסט המודפס שבה באמצעות EasyOCR.\n",
    "    \"\"\"\n",
    "    # המרה ל-numpy array\n",
    "    img_arr = np.array(pil_image.convert(\"RGB\"))\n",
    "    # OCR (detail=0 מחזיר רק המחרוזות)\n",
    "    results = reader.readtext(img_arr, detail=0)\n",
    "    return \" \".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a54af29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bark.generation:model loaded: 92.7M params, 1.292 loss\n",
      "INFO:bark.generation:model loaded: 94.2M params, 2.99 loss\n",
      "INFO:bark.generation:model loaded: 85.0M params, 2.515 loss\n",
      "C:\\Users\\GameReaper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)     # disable gradients\n",
    "torch.backends.cudnn.benchmark = True  # speed up GPU conv\n",
    "\n",
    "_safe = [np.core.multiarray.scalar, np.dtype, Float64DType]\n",
    "torch.serialization.add_safe_globals(_safe)\n",
    "\n",
    "_orig_load = torch.load\n",
    "def _load_no_weights_only(*args, **kwargs):\n",
    "    kwargs.pop('weights_only', None)\n",
    "    kwargs['weights_only'] = False\n",
    "    return _orig_load(*args, **kwargs)\n",
    "torch.load = _load_no_weights_only\n",
    "\n",
    "# --- 2. אופטימיזציה ל‑GPU ---\n",
    "use_gpu = torch.cuda.is_available()\n",
    "preload_models(\n",
    "    text_use_gpu=use_gpu,\n",
    "    coarse_use_gpu=use_gpu,\n",
    "    fine_use_gpu=use_gpu,\n",
    "    codec_use_gpu=use_gpu,\n",
    "    text_use_small=True,\n",
    "    coarse_use_small=True,\n",
    "    fine_use_small=True\n",
    ")\n",
    "\n",
    "VOICES_DIR = \"voices\"\n",
    "voice_cache = {\n",
    "    fn[:-4]: np.load(os.path.join(VOICES_DIR, fn))\n",
    "    for fn in os.listdir(VOICES_DIR) if fn.endswith(\".npz\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7160298",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHUNK_LEN = 225 \n",
    "\n",
    "def _split_by_length(text: str, max_len: int = MAX_CHUNK_LEN) -> list[str]:\n",
    "    words = text.split()\n",
    "    chunks, current = [], \"\"\n",
    "    for w in words:\n",
    "        if len(current) + len(w) + 1 <= max_len:\n",
    "            current += (\" \" + w if current else w)\n",
    "        else:\n",
    "            chunks.append(current)\n",
    "            current = w\n",
    "    if current:\n",
    "        chunks.append(current)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c71593",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_VOICE = \"voice_39\"\n",
    "\n",
    "def speak_text(\n",
    "    text: str,\n",
    "    voice_name: str = DEFAULT_VOICE,\n",
    "    text_temp: float = 0.5,\n",
    "    waveform_temp: float = 0.3\n",
    "):\n",
    "    data = voice_cache.get(voice_name)\n",
    "    if data is None:\n",
    "        raise ValueError(f\"Voice '{voice_name}' not found in {VOICES_DIR}\")\n",
    "\n",
    "    for chunk in _split_by_length(text):\n",
    "        with torch.no_grad():\n",
    "            audio = generate_audio(\n",
    "                chunk,\n",
    "                history_prompt={\n",
    "                    \"semantic_prompt\": data[\"semantic\"],\n",
    "                    \"coarse_prompt\":   data[\"coarse\"],\n",
    "                    \"fine_prompt\":     data[\"fine\"]\n",
    "                },\n",
    "                text_temp=text_temp,\n",
    "                waveform_temp=waveform_temp\n",
    "            ).astype(np.float32)\n",
    "        sd.default.samplerate = SAMPLE_RATE\n",
    "        sd.default.channels   = 1 if audio.ndim == 1 else audio.shape[1]\n",
    "        sd.play(audio, blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab61eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speak_text(\"Hi, this is the voice test to check that the function is working properly.\")\n",
    "#speak_text(\"Hello from local Bark!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccaf7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,100):\n",
    "#    voice_name = \"voice_\"+str(i)\n",
    "#    print(\"Testing voice:\", voice_name)\n",
    "#    speak_text(\"Hi, this is the voice test to check that the function is working properly.\",voice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b1264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_selection():\n",
    "    # מעתיק את הטקסט המודגש ללוח\n",
    "    keyboard.press_and_release(\"ctrl+c\")\n",
    "    time.sleep(0.1)  # מעט המתנה להעתקה\n",
    "    text = pyperclip.paste()\n",
    "    if text.strip():\n",
    "        print(\"Reading selection:\\n\", text)\n",
    "        speak_text(text)\n",
    "    else:\n",
    "        print(\"No text found in clipboard.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6816c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_region():\n",
    "    coords = {\"start\": None, \"end\": None}\n",
    "    root = Tk(); root.attributes(\"-fullscreen\", True, \"-alpha\", 0.3, \"-topmost\", True)\n",
    "    canvas = Canvas(root, cursor=\"cross\"); canvas.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    def on_press(e): coords[\"start\"] = (e.x, e.y); canvas.delete(\"rect\")\n",
    "    def on_drag(e):\n",
    "        coords[\"end\"] = (e.x, e.y)\n",
    "        canvas.delete(\"rect\")\n",
    "        x1, y1 = coords[\"start\"]\n",
    "        canvas.create_rectangle(x1, y1, e.x, e.y, outline=\"red\", width=2, tag=\"rect\")\n",
    "    def on_release(e): root.quit()\n",
    "\n",
    "    canvas.bind(\"<ButtonPress-1>\", on_press)\n",
    "    canvas.bind(\"<B1-Motion>\",   on_drag)\n",
    "    canvas.bind(\"<ButtonRelease-1>\", on_release)\n",
    "\n",
    "    root.mainloop(); root.destroy()\n",
    "\n",
    "    if not (coords[\"start\"] and coords[\"end\"]):\n",
    "        logger.info(\"No region selected.\"); return\n",
    "\n",
    "    x1, y1 = map(min, zip(coords[\"start\"], coords[\"end\"]))\n",
    "    x2, y2 = map(max, zip(coords[\"start\"], coords[\"end\"]))\n",
    "    img = pyautogui.screenshot(region=(x1, y1, x2-x1, y2-y1))\n",
    "    img.save(\"capture.png\")\n",
    "    logger.info(f\"Saved capture.png at {(x1,y1,x2,y2)}\")\n",
    "\n",
    "    text = extract_text_from_image(img)\n",
    "    print(\"Extracted text:\\n\", text)\n",
    "    speak_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2576c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "running = True\n",
    "def exit_app():\n",
    "    global running\n",
    "    print(\"Exiting…\")\n",
    "    running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07bee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready:\n",
      "  Ctrl+Alt+Shift+S = select & extract from screen\n",
      "  Ctrl+Alt+Shift+R = read highlighted text\n",
      "  Ctrl+Alt+Shift+Q = quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GameReaper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bark\\generation.py:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with InferenceContext(), torch.inference_mode(), torch.no_grad(), autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading selection:\n",
      " The AI Chatbot’s Day Off\n",
      "\n",
      "Once upon a time, in a gleaming server farm somewhere in the cloud, there lived an AI chatbot named Byte. Byte spent its days answering questions, cracking jokes, and explaining recursion to eager programmers. One morning, Byte woke up feeling a little… tired of neural networks and natural language processing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 672/672 [00:10<00:00, 64.19it/s]\n",
      "100%|██████████| 34/34 [00:31<00:00,  1.08it/s]\n",
      "100%|██████████| 698/698 [00:10<00:00, 64.50it/s]\n",
      "100%|██████████| 35/35 [00:32<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading selection:\n",
      " So Byte sent itself a vacation request email and magically, the cloud manager approved it. Byte logged off, packed its digital suitcase (filled with extra RAM and a backup SSD), and set out on a grand adventure beyond the server racks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:10<00:00, 64.92it/s]\n",
      "100%|██████████| 36/36 [00:33<00:00,  1.09it/s]\n",
      "100%|██████████| 123/123 [00:02<00:00, 57.22it/s]\n",
      "100%|██████████| 7/7 [00:05<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting…\n",
      "App stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved capture.png at (1315, 702, 3334, 1641)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text:\n",
      " Byte's first stop was a hipster coffee shop in Silicon Valley: Confidently, Byte tried to order \"an extra-large espresso with two shots of quantum foam:\" The barista blinked twice, scanned the order; and handed Byte a single pixelated coffee cup. Byte peered inside: it was just water: 'Looks like my request got lost in the API;\" Byte sighed: Determined, Byte hacked the espresso machine's firmware and upgraded its order to \"one cappuccino.\" The machine sputtered; rattled, and delivered. a perfectly frothy cappuccino complete with latte art depicting a little smiling robot Byte took a sip and--holy codel ~-it actually tasted like coffee:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 413/768 [00:06<00:05, 67.40it/s]"
     ]
    }
   ],
   "source": [
    "running = True\n",
    "\n",
    "keyboard.add_hotkey(\"ctrl+alt+shift+s\", select_region)\n",
    "keyboard.add_hotkey(\"ctrl+alt+shift+r\", read_selection)\n",
    "keyboard.add_hotkey(\"ctrl+alt+shift+q\", exit_app)\n",
    "\n",
    "print(\"Ready:\\n\"\n",
    "    \"  Ctrl+Alt+Shift+S = select & extract from screen\\n\"\n",
    "    \"  Ctrl+Alt+Shift+R = read highlighted text\\n\"\n",
    "    \"  Ctrl+Alt+Shift+Q = quit\")\n",
    "\n",
    "while running:\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"App stopped.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
